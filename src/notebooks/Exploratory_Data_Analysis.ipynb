{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics \n",
    "### Aim \n",
    "- Obtain basic statistics for textual lengths (like headline length).\n",
    "- Count the number of articles per publisher to identify which publishers are most active.\n",
    "- Analyze the publication dates to see trends over time, such as increased news frequency on particular days or during specific events.\n",
    "# \n",
    "### Technical Appraoch \n",
    "- use modular implementation as much as possible \n",
    "- cleanup code \n",
    "- calculate basic Technical indicators \n",
    "- visualize Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset and useful libraries \n",
    "import os \n",
    "import pandas as pd \n",
    "os.chdir('../scripts/')\n",
    "import utils as util\n",
    "\n",
    "\n",
    "data_path = \"../../data/week1/raw_analyst_ratings.csv\"\n",
    "df = util.read_csv_file(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0            Stocks That Hit 52-Week Highs On Friday   \n",
       "1         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2                      71 Biggest Movers From Friday   \n",
       "3       46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4  B of A Securities Maintains Neutral on Agilent...   \n",
       "\n",
       "                                                 url          publisher  \\\n",
       "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "\n",
       "                        date stock  \n",
       "0  2020-06-05 10:30:54-04:00     A  \n",
       "1  2020-06-03 10:45:20-04:00     A  \n",
       "2  2020-05-26 04:30:07-04:00     A  \n",
       "3  2020-05-22 12:45:06-04:00     A  \n",
       "4  2020-05-22 11:38:59-04:00     A  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.get(\"data\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain basic statistics for textual lengths (like headline length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1407328.0\n",
       "mean          73.0\n",
       "std           40.0\n",
       "min            3.0\n",
       "25%           47.0\n",
       "50%           64.0\n",
       "75%           87.0\n",
       "max          512.0\n",
       "Name: headline_length, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the length of each headline\n",
    "df['headline_length'] = df['headline'].apply(len)\n",
    "\n",
    "# Obtain basic statistics for headline lengths and also change it to integer to make more sense \n",
    "headline_length_stats = df['headline_length'].describe().apply(lambda x: int(x) if not x.is_integer() else x)\n",
    "\n",
    "# Display the statistics\n",
    "headline_length_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of articles per publisher to identify which publishers are most active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Paul Quintaro        228373\n",
       "Lisa Levin           186979\n",
       "Benzinga Newsdesk    150484\n",
       "Charles Gross         96732\n",
       "Monica Gerson         82380\n",
       "Eddie Staley          57254\n",
       "Hal Lindon            49047\n",
       "ETF Professor         28489\n",
       "Juan Lopez            28438\n",
       "Benzinga Staff        28114\n",
       "Vick Meyer            24826\n",
       "webmaster             20313\n",
       "Benzinga_Newsdesk     19410\n",
       "Zacks                 19390\n",
       "Jayson Derrick        19050\n",
       "Allie Wickman         18317\n",
       "Shanthi Rexaline      16640\n",
       "Craig Jones           16221\n",
       "Wayne Duggan          12897\n",
       "Nelson Hem            12590\n",
       "Name: publisher, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of articles per publisher\n",
    "articles_per_publisher = df['publisher'].value_counts()\n",
    "\n",
    "# Display top 20 articles per publisher  \n",
    "articles_per_publisher[:20] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the publication dates to see trends over time, such as increased news frequency on particular days or during specific events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime format with UTC conversion to handle tz-aware values\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce', utc=True)\n",
    "\n",
    "# Drop rows with invalid date values\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# Convert to local time zone if needed (e.g., 'America/New_York')\n",
    "df['date'] = df['date'].dt.tz_convert('America/New_York')\n",
    "\n",
    "# Extract the date part only (without time)\n",
    "df['date_only'] = df['date'].dt.date\n",
    "\n",
    "# Extract the day of the week\n",
    "df['day_of_week'] = df['date'].dt.day_name()\n",
    "\n",
    "# Count the number of articles per day\n",
    "articles_per_day = df['date_only'].value_counts().sort_index()\n",
    "\n",
    "# Count the number of articles per day of the week\n",
    "articles_per_day_of_week = df['day_of_week'].value_counts().sort_index()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009-02-13      1\n",
       "2009-04-26      2\n",
       "2009-04-28      1\n",
       "2009-05-21      1\n",
       "2009-05-26      6\n",
       "             ... \n",
       "2020-06-07     25\n",
       "2020-06-08    765\n",
       "2020-06-09    804\n",
       "2020-06-10    806\n",
       "2020-06-11    544\n",
       "Name: date_only, Length: 3976, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of articles per day\n",
    "articles_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Friday        16854\n",
       "Monday       295793\n",
       "Saturday      16344\n",
       "Sunday       255278\n",
       "Thursday     221207\n",
       "Tuesday      300060\n",
       "Wednesday    301792\n",
       "Name: day_of_week, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the number of articles per day of the week\n",
    "articles_per_day_of_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Analysis(Sentiment analysis & Topic Modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform sentiment analysis on headlines to gauge the sentiment (positive, negative, neutral) associated with the news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to get sentiment\n",
    "def get_sentiment(headline):\n",
    "    analysis = TextBlob(headline)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "# Apply sentiment analysis on headlines\n",
    "df['sentiment'] = df['headline'].apply(get_sentiment)\n",
    "\n",
    "# Display the first few rows to check the sentiment column\n",
    "df[['headline', 'sentiment']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Function to display topics\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "# Extract keywords/phrases using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['headline'])\n",
    "\n",
    "# Apply Latent Dirichlet Allocation (LDA) to extract topics\n",
    "lda = LatentDirichletAllocation(n_components=10, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Display the topics\n",
    "no_top_words = 10\n",
    "display_topics(lda, vectorizer.get_feature_names_out(), no_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
