{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries \n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from textblob import TextBlob \n",
    "os.chdir('../scripts/')\n",
    "import utils as util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Stock Data \n",
    "names = [\"AAPL\",\"AMZN\",\"GOOG\",\"META\",\"MSFT\",\"NVDA\",\"TSLA\"]\n",
    "stock_data = pd.DataFrame()\n",
    "for name in names: \n",
    "    # read data \n",
    "    data_path = f\"../../data/week1/yfinance_data/{name}_historical_data.csv\"\n",
    "    curr_data = util.read_csv_file(data_path).get(\"data\")\n",
    "    curr_data[\"stock\"] = name \n",
    "\n",
    "    # concatenate \n",
    "    stock_data = pd.concat([stock_data,curr_data],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import News Data \n",
    "data_path = \"../../data/week1/raw_analyst_ratings.csv\"\n",
    "df = util.read_csv_file(data_path)\n",
    "news_data = df.get(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Dates \n",
    "- For both data normalize the dates \n",
    "- To normalize we have to change it date only with no time component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'date' column is not in datetime format. Please check the conversion.\n"
     ]
    }
   ],
   "source": [
    "# Convert 'date' in news_data\n",
    "news_data['date'] = pd.to_datetime(news_data['date'], errors='coerce')  # Convert to datetime\n",
    "\n",
    "# Check the data type and handle NaT values\n",
    "if news_data['date'].isnull().any():\n",
    "    print(\"There are NaT values in the 'date' column. Please check the original data.\")\n",
    "    # Optionally, you can drop NaT values or fill them\n",
    "    # news_data = news_data.dropna(subset=['date'])  # Drop rows with NaT\n",
    "    # news_data['date'] = news_data['date'].fillna(pd.Timestamp('some_default_date'))  # Fill with a default date\n",
    "\n",
    "# Proceed only if the conversion was successful\n",
    "if pd.api.types.is_datetime64_any_dtype(news_data['date']):\n",
    "    news_data['date'] = news_data['date'].dt.tz_convert('UTC')  # Remove timezone\n",
    "    news_data['date'] = news_data['date'].dt.date  # Extract only the date\n",
    "else:\n",
    "    print(\"The 'date' column is not in datetime format. Please check the conversion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Sentiment Analysis on News Headlines\n",
    "def analyze_sentiment(headline):\n",
    "    \"\"\"Analyzes the sentiment of a headline and returns a polarity score.\"\"\"\n",
    "    return TextBlob(headline).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Data Preparation\n",
    "news_data['sentiment_score'] = news_data['headline'].apply(analyze_sentiment)\n",
    "\n",
    "# Align the dates between news and stock data by merging on date and stock symbol\n",
    "merged_data = pd.merge(news_data, stock_data, left_on=['date', 'stock'], right_on=['Date', 'stock'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Calculate Stock Movements\n",
    "# Calculate daily returns as the percentage change in 'Close' prices\n",
    "stock_data['daily_return'] = stock_data['Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Aggregate Sentiments\n",
    "# Calculate the average daily sentiment score for each stock and each date\n",
    "average_sentiment = news_data.groupby(['date', 'stock'])['sentiment_score'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the aggregated sentiment data with stock data\n",
    "final_merged_data = pd.merge(stock_data, average_sentiment, left_on=['Date', 'stock'], right_on=['date', 'stock'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Correlation Analysis\n",
    "# Drop rows with missing values to ensure clean correlation analysis\n",
    "clean_data = final_merged_data.dropna(subset=['daily_return', 'sentiment_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Pearson correlation coefficient between daily returns and sentiment scores\n",
    "correlation = clean_data['daily_return'].corr(clean_data['sentiment_score'])\n",
    "print(f\"The Pearson correlation coefficient between daily stock returns and sentiment scores is: {correlation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
